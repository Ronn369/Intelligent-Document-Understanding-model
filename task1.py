# -*- coding: utf-8 -*-
"""task1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zJ0f3kS5-cKKwlEHpxn6OXfiyNv_oZ5y
"""

import pytesseract
from PIL import Image


# from google.colab import drive
# drive.mount('/content/drive')



import pytesseract
from PIL import Image
import os

img_folder = "invoices"
print(os.listdir(img_folder))  # just to verify images are listed

for file in os.listdir(img_folder):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        img_path = os.path.join(img_folder, file)
        text = pytesseract.image_to_string(Image.open(img_path))
        print(f"Text from {file}:\n", text)
        print("-" * 50)

import pytesseract
from PIL import Image
import os
import json


img_folder = "/content/drive/MyDrive/ ai-document-project/data/invoices"


data = {}


for file in os.listdir(img_folder):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        img_path = os.path.join(img_folder, file)
        text = pytesseract.image_to_string(Image.open(img_path))
        data[file] = {"extracted_text": text.strip()}


json_output = json.dumps(data, indent=4)

output_path = "/content/drive/MyDrive/ ai-document-project/output_ocr.json"
with open(output_path, "w", encoding="utf-8") as json_file:
    json_file.write(json_output)


print("\n Extracted JSON Output:\n")
print(json_output)

print(f"\n Extracted text also saved to: {output_path}")

import pytesseract
from PIL import Image
import os
import json


img_folder = "/content/drive/MyDrive/ ai-document-project/data/invoices"

data = {}


doc_keywords = {
    "Invoice": ["invoice", "total amount", "bill to", "gst", "tax", "invoice no"],
    "Purchase Order": ["purchase order", "po number", "supplier", "buyer", "order date"],
    "Resume": ["education", "skills", "experience", "projects", "objective"]
}

def classify_document(text):
    text_lower = text.lower()
    for doc_type, keywords in doc_keywords.items():
        for word in keywords:
            if word in text_lower:
                return doc_type
    return "Unknown"


for file in os.listdir(img_folder):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        img_path = os.path.join(img_folder, file)
        text = pytesseract.image_to_string(Image.open(img_path))
        classification = classify_document(text)

        data[file] = {
            "extracted_text": text.strip(),
            "document_type": classification
        }

json_output = json.dumps(data, indent=4)


output_path = "/content/drive/MyDrive/ ai-document-project/output_ocr_with_classification.json"
with open(output_path, "w", encoding="utf-8") as json_file:
    json_file.write(json_output)


print("\n Extracted and Classified Data (JSON):\n")
print(json_output)

print(f"\n Extracted text and classification saved to: {output_path}")

import pytesseract
from PIL import Image
import os
import json
import re


img_folder = "/content/drive/MyDrive/ ai-document-project/data"


data = {}


doc_keywords = {
    "Invoice": ["invoice", "total amount", "bill to", "gst", "tax", "invoice no"],
    "Purchase Order": ["purchase order", "po number", "supplier", "buyer", "order date"],
    "Resume": ["education", "skills", "experience", "projects", "objective"]
}


def classify_document(text):
    text_lower = text.lower()
    for doc_type, keywords in doc_keywords.items():
        for word in keywords:
            if word in text_lower:
                return doc_type
    return "Unknown"


def extract_invoice_fields(text):
    fields = {}


    invoice_no = re.search(r"(invoice\s*(no\.?|number)?\s*[:\-]?\s*\w+)", text, re.IGNORECASE)
    date = re.search(r"(\b\d{1,2}[\/\-]\d{1,2}[\/\-]\d{2,4}\b)", text)
    total = re.search(r"(total\s*(amount)?\s*[:\-]?\s*\$?\s*\d+(\.\d{2})?)", text, re.IGNORECASE)

    if invoice_no:
        fields["invoice_number"] = invoice_no.group(0)
    if date:
        fields["date"] = date.group(0)
    if total:
        fields["total_amount"] = total.group(0)

    return fields


def reasoning_logic(doc_type, fields):
    explanation = []
    flags = []

    if doc_type == "Invoice":
        if "total_amount" in fields:
            explanation.append(" Found total amount ‚Äî invoice seems complete.")
        else:
            explanation.append(" Missing total amount ‚Äî invoice might be incomplete.")
            flags.append("missing_total")

        if "invoice_number" not in fields:
            explanation.append(" No invoice number found.")
            flags.append("missing_invoice_no")

        if "date" not in fields:
            explanation.append(" No date found.")
            flags.append("missing_date")

    elif doc_type == "Resume":
        explanation.append(" Resume detected ‚Äî text includes education/skills/experience keywords.")

    elif doc_type == "Purchase Order":
        explanation.append(" Purchase Order detected ‚Äî includes supplier/order details.")

    else:
        explanation.append(" Document type unknown ‚Äî needs manual check.")

    return explanation, flags


for file in os.listdir(img_folder):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        img_path = os.path.join(img_folder, file)
        text = pytesseract.image_to_string(Image.open(img_path))
        doc_type = classify_document(text)
        fields = extract_invoice_fields(text)
        explanation, flags = reasoning_logic(doc_type, fields)

        data[file] = {
            "document_type": doc_type,
            "extracted_text": text.strip(),
            "key_fields": fields,
            "flags": flags,
            "explanation": explanation
        }


output_path = "/content/drive/MyDrive/ ai-document-project/output_ocr_reasoning.json"
with open(output_path, "w", encoding="utf-8") as json_file:
    json.dump(data, json_file, indent=4)


print("\n Extracted + Reasoned JSON Output:\n")
print(json.dumps(data, indent=4))

print(f"\n Extracted, reasoned data saved to: {output_path}")

import json
import os
from PIL import Image
import pytesseract


img_folder = "/content/drive/MyDrive/ ai-document-project/data/invoices"


data = {}


for file in os.listdir(img_folder):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        img_path = os.path.join(img_folder, file)
        text = pytesseract.image_to_string(Image.open(img_path))
        data[file] = {"extracted_text": text.strip()}

# Convert to formatted JSON string and print
json_output = json.dumps(data, indent=4, ensure_ascii=False)
print("Extracted JSON Output:\n")
print(json_output)

import re
import json
import os
from PIL import Image
import pytesseract


img_folder = "/content/drive/MyDrive/ ai-document-project/data/invoices"

results = {}

def classify_document(text):
    text_lower = text.lower()
    # simple keyword-based classification
    if any(word in text_lower for word in ["invoice", "bill to", "amount due", "gst", "subtotal"]):
        return "invoice"
    elif any(word in text_lower for word in ["purchase order", "po number", "supplier", "delivery date"]):
        return "purchase_order"
    elif any(word in text_lower for word in ["resume", "curriculum vitae", "education", "skills", "experience"]):
        return "resume"
    else:
        return "unknown"

for file in os.listdir(img_folder):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        img_path = os.path.join(img_folder, file)
        text = pytesseract.image_to_string(Image.open(img_path))

        doc_type = classify_document(text)

        results[file] = {
            "document_type": doc_type,
            "extracted_text": text.strip()
        }

# print nicely
print(json.dumps(results, indent=4, ensure_ascii=False))

import json
import re

def classify_document(text):
    """Classify the type of document based on keywords."""
    text_lower = text.lower()
    if "invoice" in text_lower or "total amount" in text_lower:
        return "Invoice"
    elif "purchase order" in text_lower or "supplier" in text_lower:
        return "Purchase Order"
    elif "resume" in text_lower or "skills" in text_lower or "experience" in text_lower:
        return "Resume"
    else:
        return "Unknown Document"

def extract_key_info(text):
    """Extract key fields depending on document type."""
    info = {}

    total_match = re.search(r"total[:\s]*([\d.,]+)", text, re.IGNORECASE)
    name_match = re.search(r"name[:\s]*([A-Za-z\s]+)", text, re.IGNORECASE)
    date_match = re.search(r"(\d{2}[/-]\d{2}[/-]\d{4})", text)

    if total_match:
        info["total_amount"] = total_match.group(1)
    if name_match:
        info["name"] = name_match.group(1)
    if date_match:
        info["date"] = date_match.group(1)

    return info

structured_data = []

for file in os.listdir(img_folder):
    if file.endswith(('.png', '.jpg', '.jpeg')):
        img_path = os.path.join(img_folder, file)
        text = pytesseract.image_to_string(Image.open(img_path))

        doc_type = classify_document(text)
        key_info = extract_key_info(text)

        structured_data.append({
            "file_name": file,
            "document_type": doc_type,
            "extracted_info": key_info,
            "raw_text": text[:500]
        })


with open("structured_output.json", "w", encoding="utf-8") as f:
    json.dump(structured_data, f, indent=4, ensure_ascii=False)


print(json.dumps(structured_data, indent=4))

#this is the section where i am doing extra and after this i will start the deployment



import speech_recognition as sr
from gtts import gTTS
from IPython.display import Audio, display
import os

def speak_text(text):
    """Convert text to speech and play it."""
    tts = gTTS(text=text, lang='en')
    tts.save("response.mp3")
    display(Audio("response.mp3", autoplay=True))

def listen_command():
    """Capture a voice command from microphone (useful in local runs)."""
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("üéôÔ∏è Speak now...")
        audio = recognizer.listen(source)
    try:
        command = recognizer.recognize_google(audio)
        print("üó£Ô∏è You said:", command)
        return command.lower()
    except sr.UnknownValueError:
        print(" Sorry, I didn‚Äôt catch that.")
        return ""

import json
from gtts import gTTS
from IPython.display import Audio, display
import time

with open("structured_output.json", "r", encoding="utf-8") as f:
    data = json.load(f)

for i, doc in enumerate(data, start=1):
    summary = f"This is a {doc['document_type']} document. "
    fields = doc.get("extracted_info", {})

    if "name" in fields:
        summary += f"The document belongs to {fields['name']}. "
    if "total_amount" in fields:
        summary += f"The total amount is {fields['total_amount']}. "
    if "date" in fields:
        summary += f"It is dated {fields['date']}. "

    summary += " End of document summary."

    print(f"\nüìÑ Summary {i}: {summary}\n")


    filename = f"summary_{i}.mp3"
    tts = gTTS(text=summary, lang='en')
    tts.save(filename)


    display(Audio(filename, autoplay=True))


    time.sleep(3)


import json
import networkx as nx
from pyvis.network import Network

# Load structured data
with open("structured_output.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# Create a graph
G = nx.Graph()

# Build relationships
for i, doc in enumerate(data, start=1):
    doc_node = f"{doc['document_type']} {i}"
    G.add_node(doc_node, title="Document")

    fields = doc.get("extracted_info", {})
    for key, value in fields.items():
        entity_node = f"{key}: {value}"
        G.add_node(entity_node, title=key)
        G.add_edge(doc_node, entity_node)

# Convert to interactive visualization
net = Network(notebook=True, height="600px", width="100%", bgcolor="#222222", font_color="white")
net.from_nx(G)
net.show("knowledge_graph.html")

#we are starting the deployment process


